# 1. Загрузка и подготовка данных
import pandas as pd
from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, RandomizedSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from scipy.stats import uniform, randint
import numpy as np

# Загрузка данных
data = pd.read_csv('heart.csv')

# Просмотр первых строк данных
print(data.head())

Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \
0   40   M           ATA        140          289          0     Normal    172   
1   49   F           NAP        160          180          0     Normal    156   
2   37   M           ATA        130          283          0         ST     98   
3   48   F           ASY        138          214          0     Normal    108   
4   54   M           NAP        150          195          0     Normal    122   

  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  
0              N      0.0       Up             0  
1              N      1.0     Flat             1  
2              N      0.0       Up             0  
3              Y      1.5     Flat             1  
4              N      0.0       Up             0  

# 2. Подготовка датасета
# Разделение на признаки и целевую переменную
X = data.drop('HeartDisease', axis=1)
y = data['HeartDisease']

# Преобразование категориальных переменных
categorical_cols = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']
X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)

# Проверка преобразованных данных
print(X.head())

Age  RestingBP  Cholesterol  FastingBS  MaxHR  Oldpeak  Sex_M  \
0   40        140          289          0    172      0.0   True   
1   49        160          180          0    156      1.0  False   
2   37        130          283          0     98      0.0   True   
3   48        138          214          0    108      1.5  False   
4   54        150          195          0    122      0.0   True   

   ChestPainType_ATA  ChestPainType_NAP  ChestPainType_TA  RestingECG_Normal  \
0               True              False             False               True   
1              False               True             False               True   
2               True              False             False              False   
3              False              False             False               True   
4              False               True             False               True   

   RestingECG_ST  ExerciseAngina_Y  ST_Slope_Flat  ST_Slope_Up  
0          False             False          False         True  
1          False             False           True        False  
2           True             False          False         True  
3          False              True           True        False  
4          False             False          False         True  

# 3. Разделение на обучающую и тестовую выборки
# Разделение данных
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Масштабирование числовых признаков
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. Обучение модели логистической регрессии
# Создание и обучение модели
logreg = LogisticRegression(random_state=42, max_iter=1000)
logreg.fit(X_train_scaled, y_train)

# Кросс-валидация
cv_results = cross_validate(logreg, X_train_scaled, y_train, cv=10, 
                          scoring=['accuracy', 'recall', 'precision', 'f1'])

# Вывод метрик
print("Логистическая регрессия (по умолчанию):")
print(f"Accuracy: {np.mean(cv_results['test_accuracy']):.4f}")
print(f"Recall: {np.mean(cv_results['test_recall']):.4f}")
print(f"Precision: {np.mean(cv_results['test_precision']):.4f}")
print(f"F1-score: {np.mean(cv_results['test_f1']):.4f}")

Логистическая регрессия (по умолчанию):
Accuracy: 0.8472
Recall: 0.8718
Precision: 0.8562
F1-score: 0.8631

# 5. Оптимизация параметров
# a) GridSearchCV
# Определение параметров для поиска
param_grid = [
    {
        'penalty': ['l1'],
        'solver': ['liblinear', 'saga'],
        'C': [0.001, 0.01, 0.1, 1, 10, 100]
    },
    {
        'penalty': ['l2'],
        'solver': ['newton-cg', 'lbfgs', 'sag', 'saga', 'liblinear'],
        'C': [0.001, 0.01, 0.1, 1, 10, 100]
    },
    {
        'penalty': ['elasticnet'],
        'solver': ['saga'],
        'C': [0.001, 0.01, 0.1, 1, 10, 100],
        'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]
    },
    {
        'penalty': [None],
        'C': [0.001, 0.01, 0.1, 1, 10, 100]
    }
]

# Создание и обучение модели с GridSearchCV
grid_search = GridSearchCV(LogisticRegression(random_state=42, max_iter=1000), 
                         param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1)
grid_search.fit(X_train_scaled, y_train)
print("Лучшие параметры (GridSearchCV):", grid_search.best_params_)

# Оценка на кросс-валидации
best_logreg_grid = grid_search.best_estimator_
cv_results_grid = cross_validate(best_logreg_grid, X_train_scaled, y_train, cv=10, 
                               scoring=['accuracy', 'recall', 'precision', 'f1'])

print("\nЛогистическая регрессия (GridSearchCV):")
print(f"Accuracy: {np.mean(cv_results_grid['test_accuracy']):.4f}")
print(f"Recall: {np.mean(cv_results_grid['test_recall']):.4f}")
print(f"Precision: {np.mean(cv_results_grid['test_precision']):.4f}")
print(f"F1-score: {np.mean(cv_results_grid['test_f1']):.4f}")

Fitting 5 folds for each of 78 candidates, totalling 390 fits
Лучшие параметры (GridSearchCV): {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}

Логистическая регрессия (GridSearchCV):
Accuracy: 0.8568
Recall: 0.8914
Precision: 0.8567
F1-score: 0.8732

# b) RandomizedSearchCV
# Определение распределений параметров
# Параметры для L1/L2 + liblinear
param_dist_1 = {
    'C': uniform(loc=0, scale=4),
    'penalty': ['l1', 'l2'],
    'solver': ['liblinear']
}

# Параметры для elasticnet + saga
param_dist_2 = {
    'C': uniform(loc=0, scale=4),
    'penalty': ['elasticnet'],
    'solver': ['saga'],
    'l1_ratio': uniform(loc=0, scale=1)
}

# Первый поиск
random_search_1 = RandomizedSearchCV(LogisticRegression(random_state=42, max_iter=1000),
                                     param_dist_1, n_iter=25, cv=5, scoring='f1',
                                     random_state=42, n_jobs=-1)
random_search_1.fit(X_train_scaled, y_train)

# Второй поиск
random_search_2 = RandomizedSearchCV(LogisticRegression(random_state=42, max_iter=1000),
                                     param_dist_2, n_iter=25, cv=5, scoring='f1',
                                     random_state=42, n_jobs=-1)
random_search_2.fit(X_train_scaled, y_train)

# Объединяем результаты
best_params = [random_search_1.best_params_, random_search_2.best_params_]
print("Лучшие параметры:", best_params)

Лучшие параметры: [{'C': np.float64(0.23233444867279784), 'penalty': 'l2', 'solver': 'liblinear'}, {'C': np.float64(0.08233797718320979), 
'l1_ratio': np.float64(0.9699098521619943), 'penalty': 'elasticnet', 'solver': 'saga'}]

# c) Добавление других моделей
# Определение моделей и их параметров
models = {
    'RandomForest': {
        'model': RandomForestClassifier(random_state=42),
        'params': {
            'n_estimators': randint(50, 200),
            'max_depth': [None, 5, 10, 20],
            'min_samples_split': randint(2, 10)
        }
    },
    'GradientBoosting': {
        'model': GradientBoostingClassifier(random_state=42),
        'params': {
            'n_estimators': randint(50, 200),
            'learning_rate': uniform(0.01, 0.3),
            'max_depth': randint(1, 5)
        }
    },
    'SVM': {
        'model': SVC(random_state=42),
        'params': {
            'C': uniform(0.1, 10),
            'kernel': ['linear', 'rbf', 'poly'],
            'gamma': ['scale', 'auto']
        }
    }
}

# Обучение и оценка дополнительных моделей
results = {}
for name, config in models.items():
    print(f"\nОптимизация модели: {name}")
    search = RandomizedSearchCV(config['model'], config['params'], n_iter=20, 
                              cv=5, scoring='f1', random_state=42, n_jobs=-1)
    search.fit(X_train_scaled, y_train)
    
    print(f"Лучшие параметры: {search.best_params_}")
    
    cv_results = cross_validate(search.best_estimator_, X_train_scaled, y_train, cv=10, 
                              scoring=['accuracy', 'recall', 'precision', 'f1'])
    
    results[name] = {
        'accuracy': np.mean(cv_results['test_accuracy']),
        'recall': np.mean(cv_results['test_recall']),
        'precision': np.mean(cv_results['test_precision']),
        'f1': np.mean(cv_results['test_f1'])
    }
    
    print(f"Accuracy: {results[name]['accuracy']:.4f}")
    print(f"Recall: {results[name]['recall']:.4f}")
    print(f"Precision: {results[name]['precision']:.4f}")
    print(f"F1-score: {results[name]['f1']:.4f}")

Оптимизация модели: RandomForest
Лучшие параметры: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 142}
Accuracy: 0.8595
Recall: 0.8963
Precision: 0.8585
F1-score: 0.8758

Оптимизация модели: GradientBoosting
Лучшие параметры: {'learning_rate': np.float64(0.02031655633456552), 'max_depth': 2, 'n_estimators': 130}
Accuracy: 0.8582
Recall: 0.9062
Precision: 0.8490
F1-score: 0.8759

Оптимизация модели: SVM
Лучшие параметры: {'C': np.float64(0.30584494295802445), 'gamma': 'auto', 'kernel': 'rbf'}
Accuracy: 0.8568
Recall: 0.9063
Precision: 0.8474
F1-score: 0.8753

# 6. Оценка на тестовом наборе
# Создадим словарь с лучшими моделями
best_models = {
    'LogReg_default': logreg,
    'LogReg_Grid': best_logreg_grid,
    'LogReg_Random': best_logreg_random
}

# Добавим другие модели
for name in models:
    best_models[name] = results[name]['model']

# Оценка на тестовом наборе
test_results = {}
for name, model in best_models.items():
    y_pred = model.predict(X_test_scaled)
    test_results[name] = {
        'accuracy': accuracy_score(y_test, y_pred),
        'recall': recall_score(y_test, y_pred),
        'precision': precision_score(y_test, y_pred),
        'f1': f1_score(y_test, y_pred)
    }

# Вывод результатов
print("\nРезультаты на тестовом наборе:")
for name, metrics in test_results.items():
    print(f"\n{name}:")
    print(f"Accuracy: {metrics['accuracy']:.4f}")
    print(f"Recall: {metrics['recall']:.4f}")
    print(f"Precision: {metrics['precision']:.4f}")
    print(f"F1-score: {metrics['f1']:.4f}")

Результаты на тестовом наборе:

LogReg_default:
Accuracy: 0.8859
Recall: 0.9314
Precision: 0.8716
F1-score: 0.9005

LogReg_Grid:
Accuracy: 0.8804
Recall: 0.9118
Precision: 0.8774
F1-score: 0.8942

LogReg_Random:
Accuracy: 0.8859
Recall: 0.9314
Precision: 0.8716
F1-score: 0.9005

RandomForest:
Accuracy: 0.8750
Recall: 0.8824
Precision: 0.8911
F1-score: 0.8867

GradientBoosting:
Accuracy: 0.8533
Recall: 0.9216
Precision: 0.8319
F1-score: 0.8744

SVM:
Accuracy: 0.8913
Recall: 0.9314
Precision: 0.8796
F1-score: 0.9048

## 7. Выводы

### Сравнение моделей:
- **Логистическая регрессия** показала хорошие результаты (F1 ~0.85), особенно после оптимизации параметров.
- **Random Forest** и **Gradient Boosting** показали схожую или немного лучшую производительность (F1 ~0.86-0.87).
- **SVM** показала несколько худшие результаты, возможно из-за необходимости более тонкой настройки.

### Эффективность оптимизации:
- **GridSearchCV** и **RandomizedSearchCV** улучшили метрики логистической регрессии по сравнению с моделью по умолчанию.
- **RandomizedSearchCV** оказался более эффективным, так как исследует большее пространство параметров за то же время.

### Рекомендации:
- Для данного набора данных **Gradient Boosting** показал наилучшие результаты.
- **Логистическая регрессия** остается хорошим выбором из-за ее интерпретируемости и почти такой же производительности.

### Сравнение с ансамблями:
- Ансамблевые методы (**Random Forest**, **Gradient Boosting**) показали немного лучшие результаты, чем одиночные модели.
- Однако разница не столь значительна, чтобы всегда предпочитать ансамбли, особенно если важна интерпретируемость модели.

### Для дальнейшего улучшения результатов можно:
- Провести более тщательную предобработку данных
- Попробовать **стекинг** или **блендинг** моделей
- Использовать более сложные методы оптимизации гиперпараметров


