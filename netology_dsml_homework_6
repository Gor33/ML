#**Цель: изучить применение дерева решений в рамках задачи регрессии**

git commit -m '
Описание задания: 

В домашнем задании нужно решить задачу регрессии. В качестве датасета необходимо взять данные о недвижимости Калифорнии из библиотеки sklearn.datasets. Целевая переменная – MedHouseVal. 
Прочитать информацию о признаках датасета можно, выполнив следующий код – print(fetch_california_housing().DESCR). На полученных данных построить модель регрессии и дерево решений.

Этапы работы:

1. Получите данные и загрузите их в рабочую среду. (Jupyter Notebook или другую).

2. Проведите первичный анализ.

a.Проверьте данные на пропуски. Удалите в случае обнаружения.

b.*Нормализуйте один из признаков.

3. Разделите выборку на обучающее и тестовое подмножества. 80% данных оставить на обучающее множество, 20% - на тестовое.

4. Обучите модель регрессии на обучающем множестве.

5. Для тестового множества предскажите целевую переменную и сравните с истинным значением, посчитав точность предсказания модели. Для этого используйте встроенную функцию score.

6. Обучите дерево решений на обучающем множестве.

a. Повторите п. 5 для полученной модели.

b. Визуализируйте часть дерева решений. Убедитесь, что график получился читабельным. Посмотрите примеры визуализации по ссылке.

7. Оптимизируйте глубину дерева (max_depth). *Оптимизируйте ещё один параметр модели на выбор.

a. Повторите п. 5 для полученной модели.

8. Сформулируйте выводы по проделанной работе.

a. Сравните точность двух моделей.

b. Напишите свое мнение, для каких задач предпочтительнее использовать обученные в работе модели? Какие у них есть плюсы и минусы?

9. Для получения зачета по этому домашнему заданию, должно быть как минимум реализовано обучение двух моделей, выведена их точность, оптимизирован один параметр дерева решений.'

```
from sklearn import datasets, tree
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
```

git commit -m '
1. Получите данные и загрузите их в рабочую среду. (Jupyter Notebook или другую).
2. Проведите первичный анализ.
a.Проверьте данные на пропуски. Удалите в случае обнаружения.
b.*Нормализуйте один из признаков.'

```
data = datasets.fetch_california_housing(as_frame=True).frame
data.shape
```

#(20640, 9)

```
data.info()
```

git commit -m '
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 20640 entries, 0 to 20639
Data columns (total 9 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   MedInc       20640 non-null  float64
 1   HouseAge     20640 non-null  float64
 2   AveRooms     20640 non-null  float64
 3   AveBedrms    20640 non-null  float64
 4   Population   20640 non-null  float64
 5   AveOccup     20640 non-null  float64
 6   Latitude     20640 non-null  float64
 7   Longitude    20640 non-null  float64
 8   MedHouseVal  20640 non-null  float64
dtypes: float64(9)
memory usage: 1.4 MB'

#Опытным путем мы установили, что датафрейм не содержит пропусков

```
data.head(5)
```

git commit -m '
|   | MedInc | HouseAge | AveRooms | AveBedrms | Population | AveOccup | Latitude | Longitude | MedHouseVal |   
|---|-------:|---------:|---------:|----------:|-----------:|---------:|---------:|----------:|------------:|
| 0 | 8.3252 |   1681.0 | 6.984127 |  1.023810 |   5.774552 | 1.598611 |    37.88 |   -122.23 |       4.526 |
| 1 | 8.3014 |    441.0 | 6.238137 |  0.971880 |   7.783641 | 1.452529 |    37.86 |   -122.22 |       3.585 |  
| 2 | 7.2574 |   2704.0 | 8.288136 |  1.073446 |   6.206576 | 1.673995 |    37.85 |   -122.24 |       3.521 |  
| 3 | 5.6431 |   2704.0 | 5.817352 |  1.073059 |   6.324359 | 1.596228 |    37.85 |   -122.25 |       3.413 |  
| 4 | 3.8462 |   2704.0 | 6.281853 |  1.081081 |   6.336826 | 1.476979 |    37.85 |   -122.25 |       3.422 |  
'

```
houseAgeArray = np.array(data['HouseAge'])
houseAgeArray = preprocessing.normalize([houseAgeArray])
data['HouseAge'] = houseAgeArray[0]
data.head(5)
```

git commit -m '
|   | MedInc | HouseAge | AveRooms | AveBedrms | Population | AveOccup | Latitude | Longitude | MedHouseVal |  
|---|-------:|---------:|---------:|----------:|-----------:|---------:|---------:|----------:|------------:|
| 0 | 8.3252 |   1681.0 | 6.984127 |  1.023810 |   5.774552 | 1.598611 |    37.88 |   -122.23 |       4.526 |   
| 1 | 8.3014 |    441.0 | 6.238137 |  0.971880 |   7.783641 | 1.452529 |    37.86 |   -122.22 |       3.585 |  
| 2 | 7.2574 |   2704.0 | 8.288136 |  1.073446 |   6.206576 | 1.673995 |    37.85 |   -122.24 |       3.521 |   
| 3 | 5.6431 |   2704.0 | 5.817352 |  1.073059 |   6.324359 | 1.596228 |    37.85 |   -122.25 |       3.413 |   
| 4 | 3.8462 |   2704.0 | 6.281853 |  1.081081 |   6.336826 | 1.476979 |    37.85 |   -122.25 |       3.422 |   
'

#3.Разделите выборку на обучающее и тестовое подмножества. 80% данных оставить на обучающее множество, 20% - на тестовое.
#4.Обучите модель регрессии на обучающем множестве.
#5.Для тестового множества предскажите целевую переменную и сравните с истинным значением, посчитав точность предсказания модели. Для этого используйте встроенную функцию score.

```
def get_score(X,y, random_seed=100, model=None, test_size=0.2, depth=None):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_seed)
    if model is None:
        model = LinearRegression()
        model.fit(X_train, y_train)
        return model.score(X_test, y_test)
    if model == "DTR":
        if depth==None:
            model_part = DecisionTreeRegressor(max_depth=3)
            model_part.fit(X_train, y_train)
            fig = plt.figure(figsize=(25,20))
            _ = tree.plot_tree(model_part, feature_names=data.columns, filled=True)
            model = DecisionTreeRegressor()
            model.fit(X_train, y_train)
            return model.score(X_test, y_test)
        else:
            model = DecisionTreeRegressor(max_depth=depth)
            model.fit(X_train, y_train)
            fig = plt.figure(figsize=(25,20))
            _ = tree.plot_tree(model, feature_names=data.columns, filled=True)
            return model.score(X_test, y_test)

X = data.loc[:, data.columns != "MedHouseVal"]
y = data[["MedHouseVal"]]
get_score(X, y)
```

```
0.6223138107295079
```

git commit -m '
6. Обучите дерево решений на обучающем множестве.
a. Повторите п. 5 для полученной модели.
b. Визуализируйте часть дерева решений. Убедитесь, что график получился читабельным. Посмотрите примеры визуализации по ссылке.

7. Оптимизируйте глубину дерева (max_depth). *Оптимизируйте ещё один параметр модели на выбор.
a. Повторите п. 5 для полученной модели.
'

```
get_score(X, y, model="DTR")
```

#0.6354220641956154

![](https://drive.google.com/file/d/1S35l47E9112an3yTR_skRLzhKjgKw40R/view?usp=sharing)

```
get_score(X, y, model="DTR", depth=2)
```

#0.457755892390421

![](https://drive.google.com/file/d/17IMu88_dgNvQKywC4x9DPaarl9fvO66n/view?usp=sharing)

#Расчет, score и дерева, производился с ограничением глубины. 

git commit -m '
8. Сформулируйте выводы по проделанной работе.
a. Сравните точность двух моделей.

b. Напишите свое мнение, для каких задач предпочтительнее использовать обученные в работе модели? Какие у них есть плюсы и минусы?

Дерево решений проявило себя лучше по отношению к линейной регриссии показав лучштй результат, с условием снятия ограничений на глубину. Корреляция глубины оказывает прямое влияние на точность.
Дерево решений хорошо подойдет в случае плохого знания предметной области, оно позволяет смешивать категориальные и числовые признаки. Дерево решений подвержено большей чувствительно к шумам. 
Итог: дерево решений удобно применять для быстрого получения оптимальной модели, когда исходные данные не потребуется много раз менять и, значит, перестраивать модель. 



































